{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\sheet\\\\data_final_lite.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dir_path    \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnperc\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDocuments\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDatathon\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata_image\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata_3pic\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mnperc\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDocuments\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDatathon\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mclean_deep_model\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdata\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39msheet\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdata_final_lite.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mloc[:, [\u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCHA2DS2-VASc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSexe\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\sheet\\\\data_final_lite.csv'"
     ]
    }
   ],
   "source": [
    "dir_path    = 'C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\data\\\\data_image\\\\data_3pic\\\\'\n",
    "\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_extract_model\\\\data\\\\sheet\\\\data_final_lite.csv')\n",
    "dataset = dataset.loc[:, ['ID', 'CHA2DS2-VASc', 'Age', 'Sexe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "\n",
    "image_size  = (SIZE, SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "efficient_model = EfficientNetB0(weights=None)\n",
    "\n",
    "model = Model(inputs=efficient_model.inputs, outputs=efficient_model.layers[-2].output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "error_images       = []\n",
    "patient_id_list    = []\n",
    "\n",
    "def find_images(name) :\n",
    "    data        = []\n",
    "    \n",
    "\n",
    "    for dir_client in os.listdir(dir_path) :\n",
    "        path_client = os.path.join(dir_path, dir_client)\n",
    "        for dirs in os.listdir(path_client) :\n",
    "            if dirs.lower() == name + ' od.bmp' or dirs.lower() == name + ' og.bmp' :\n",
    "                image = cv.imread(os.path.join(path_client, dirs))\n",
    "                image = cv.resize(image, (SIZE, SIZE), interpolation = cv.INTER_LINEAR)\n",
    "                \n",
    "                # image[image > 235]  -= 20\n",
    "                # image[image > 50]   += 20\n",
    "                \n",
    "                if(image[image.astype(bool)].size != 0) :\n",
    "                    try :\n",
    "                        # data = image_augmentation(data, image, model, dir_client)\n",
    "                        age     = round(dataset['Age'][dataset['ID'] == dir_client].values[0])\n",
    "                        Sexe  = int(dataset['Sexe'][dataset['ID'] == dir_client].values[0])\n",
    "                        target  = dataset['CHA2DS2-VASc'][dataset['ID'] == dir_client].values[0]\n",
    "                        patient_id_list.append(dir_client)\n",
    "                        data.append([image, age, Sexe, target])\n",
    "                    except :\n",
    "                        if dir_client not in error_images :\n",
    "                            error_images.append(dir_client)\n",
    "                        continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['image', 'age', 'Sexe', 'target']\n",
    "\n",
    "cc_images     = pd.DataFrame(find_images('cc'), columns=columns)\n",
    "sup_images    = pd.DataFrame(find_images('sup'), columns=columns)\n",
    "deep_images   = pd.DataFrame(find_images('deep'), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_col(data) :\n",
    "    columns = []\n",
    "    for col in data.columns.to_list() :\n",
    "        columns.append(str(col))\n",
    "        \n",
    "    new_columns = columns[:-3]\n",
    "    new_columns.append('age')\n",
    "    new_columns.append('Sexe')\n",
    "    new_columns.append('target')\n",
    "        \n",
    "    data.columns = new_columns\n",
    "    return data\n",
    "    \n",
    "cc_images     = form_col(cc_images)\n",
    "sup_images    = form_col(sup_images)\n",
    "deep_images   = form_col(deep_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data     = pd.read_csv('C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\cc_EfficientNetB0_ageSexe_new.csv')\n",
    "sup_data    = pd.read_csv('C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\sup_EfficientNetB0_ageSexe_new.csv')\n",
    "deep_data   = pd.read_csv('C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\deep_EfficientNetB0_ageSexe_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "age         = cc_data['age']\n",
    "sexe        = cc_data['Sexe']\n",
    "target      = cc_data['target']\n",
    "\n",
    "cc_data     = cc_data.iloc[:, :-1]\n",
    "sup_data    = sup_data.iloc[:, :-1]\n",
    "deep_data   = deep_data.iloc[:, :-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nb_pca(data, numerical_columns) :\n",
    "    data_sample = data.loc[:, numerical_columns]\n",
    "\n",
    "    data_sum = data_sample.sum().sort_values(axis=0, ascending = False)\n",
    "    sum = 0\n",
    "    for value in data_sum :\n",
    "        sum += value\n",
    "        \n",
    "    value_perc = []\n",
    "\n",
    "    sum_perc = 0\n",
    "    for i in range(len(data_sum)) :\n",
    "        \n",
    "        perc = data_sum[i] / sum\n",
    "        value_perc.append(perc)\n",
    "        sum_perc += perc\n",
    "        if sum_perc >= 0.95 :\n",
    "            break\n",
    "    return i + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction + Classification per depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def make_preprocessor(data, numeric_columns):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=find_nb_pca(data, numeric_columns))),    \n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_columns),\n",
    "        ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_col(X, binary_columns=[], categorical_columns=[]) :\n",
    "    \n",
    "    numeric_columns = []\n",
    "    for elem in X.columns.to_list():\n",
    "        if elem not in binary_columns and elem not in categorical_columns :\n",
    "            numeric_columns.append(elem)\n",
    "    return numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_y    = target\n",
    "cc_X    = cc_data\n",
    "\n",
    "sup_y   = target\n",
    "sup_X   = sup_data\n",
    "\n",
    "deep_y  = target\n",
    "deep_X  = deep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def make_forest_model(X_train, y_train) :\n",
    "    forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    forest_param = {\n",
    "        'bootstrap'         : [True],\n",
    "        'max_depth'         : [5, 8, 12, 15, 20],\n",
    "        'ccp_alpha'         : [.001],\n",
    "        'n_estimators'      : [25, 50, 100],\n",
    "        'criterion'         : ['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "    forest_grid = GridSearchCV(forest_model, forest_param)\n",
    "    \n",
    "    forest_grid.fit(X_train, y_train)\n",
    "    print(forest_grid.best_params_)\n",
    "    \n",
    "    return forest_grid.best_estimator_\n",
    "\n",
    "forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_param = {\n",
    "    'bootstrap'         : [True],\n",
    "    'max_depth'         : [5, 8, 12, 15, 20],\n",
    "    'ccp_alpha'         : [.001],\n",
    "    'n_estimators'      : [25, 50, 100],\n",
    "    'criterion'         : ['gini', 'entropy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, param=None, scoring='accuracy') :\n",
    "    \n",
    "    best_score      = 0\n",
    "    grid_list       = []\n",
    "    metric_list     = []\n",
    "    estimator_list  = []\n",
    "    \n",
    "    dict_scoring    = {\n",
    "        'accuracy'      : accuracy_score,\n",
    "        'precision'     : precision_score,\n",
    "        'recall'        : recall_score,\n",
    "        'f1'            : f1_score\n",
    "    }\n",
    "    \n",
    "    if param == None :\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred  = model.predict(X_test)\n",
    "        score   = dict_scoring[scoring](y_test, y_pred)\n",
    "        \n",
    "        grid_list.append(g)\n",
    "        estimator_list.append(model)\n",
    "        metric_list.append([score, classification_report(y_test, y_pred), confusion_matrix(y_test, y_pred)])\n",
    "        \n",
    "    else :\n",
    "        for g in ParameterGrid(param):\n",
    "            \n",
    "            model.set_params(**g)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred  = model.predict(X_test)\n",
    "            score   = dict_scoring[scoring](y_test, y_pred)\n",
    "            \n",
    "            estimator_list.append(model)\n",
    "            metric_list.append([score, classification_report(y_test, y_pred), confusion_matrix(y_test, y_pred)])\n",
    "            if score > best_score:\n",
    "                best_grid       = g\n",
    "                best_score      = score\n",
    "                best_estimator  = model\n",
    "                \n",
    "            \n",
    "    return best_estimator, best_grid, best_score, estimator_list, grid_list, metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "def dataset_split_index(X, y, test_size = 0.2, fold=None, random_state=42) :\n",
    "    \n",
    "    if fold == None :\n",
    "        data_train, data_test, labels_train, labels_test, index_train, index_test = train_test_split(X, y, X.index, test_size=test_size, random_state=random_state)\n",
    "        return [index_train, index_test]\n",
    "    else :\n",
    "        index_list  = []\n",
    "        kf          = KFold(n_splits=fold, random_state=random_state, shuffle=True)\n",
    "        for i, (index_train, index_test) in enumerate(kf.split(X)) :\n",
    "            index_list.append([index_train, index_test])\n",
    "        return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.util import random_noise\n",
    "\n",
    "  \n",
    "def form_image(image) :\n",
    "    image = image / 255.\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    return image\n",
    "\n",
    "def predict_image(image, model) :    \n",
    "    form_data = []\n",
    "    \n",
    "    for elem in model.predict(image)[0] :\n",
    "        form_data.append(elem)\n",
    "    return form_data\n",
    "  \n",
    "def image_augmentation(images, model) :\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(images)) :\n",
    "        \n",
    "        age     = round(dataset['Age'][dataset['ID'] == patient_id_list[i]].values[0])\n",
    "        Sexe  = int(dataset['Sexe'][dataset['ID'] == patient_id_list[i]].values[0])\n",
    "        \n",
    "        data.append([predict_image(form_image(images[i]), model), age, Sexe])\n",
    "\n",
    "        # data.append([predict_image(form_image(adjust_gamma(images[i], gamma=0.5,gain=1)), model), age, Sexe])\n",
    "        # data.append([predict_image(form_image(adjust_gamma(images[i], gamma=2,gain=1)), model), age, Sexe])\n",
    "        \n",
    "        data.append([predict_image(form_image(np.fliplr(images[i])), model), age, Sexe])\n",
    "        data.append([predict_image(form_image(np.flipud(images[i])), model), age, Sexe])\n",
    "        \n",
    "        # data.append([predict_image(form_image(random_noise(images[i])), model), age, Sexe])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "def preprocess_image(X, y, index_train, index_test, image_augment=False, preprocess_model=None) :\n",
    "    \n",
    "    if preprocess_model == None :\n",
    "        efficient_model     = EfficientNetB0(weights=None)\n",
    "        preprocess_model    = Model(inputs=efficient_model.inputs, outputs=efficient_model.layers[-2].output)\n",
    "    \n",
    "    X_train     = X.iloc[index_train, :]\n",
    "    y_train     = y.iloc[index_train, :]\n",
    "    \n",
    "    X_test      = X.iloc[index_test, :]\n",
    "    y_test      = y.iloc[index_test, :]\n",
    "    \n",
    "    if image_augment :\n",
    "        X_train = form_col(pd.DataFrame(image_augmentation(X_train['image'], preprocess_model)))\n",
    "    else :\n",
    "        for i in range(X_train.shape[0]) :\n",
    "            X_train['image'][i] = predict_image(form_image(X_train['image'][i]), preprocess_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_model(X, y, model, grid_param=None, fold=None, test_size = 0.2, random_state=42, image_augmentation=False, scoring='accuracy') :\n",
    "    \n",
    "    best_score      = 0    \n",
    "    report_list     = []\n",
    "    \n",
    "    for index_train, index_test in enumerate(dataset_split_index(X, y, test_size=test_size, fold=fold, random_state=random_state)) :\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = preprocess_image()\n",
    "        estimator, grid, score, estimator_list, grid_list, metric_list = train_model(model, X_train, y_train, X_test, y_test, param=grid_param, scoring=scoring)\n",
    "        \n",
    "        report_list.append(estimator, grid, score, estimator_list, grid_list, metric_list)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score      = score\n",
    "            best_estimator  = model\n",
    "    return best_estimator, best_score, report_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_preprocess   = make_preprocessor(cc_data, find_num_col(cc_data))\n",
    "sup_preprocess  = make_preprocessor(sup_data, find_num_col(sup_data))\n",
    "deep_preprocess = make_preprocessor(deep_data, find_num_col(deep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_X            = cc_preprocess.fit_transform(cc_X)\n",
    "sup_X           = sup_preprocess.fit_transform(sup_X)\n",
    "deep_X          = deep_preprocess.fit_transform(deep_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cc_X_train, cc_X_test, cc_y_train, cc_y_test            = train_test_split(cc_X, cc_y, test_size = 0.2, random_state=42)\n",
    "sup_X_train, sup_X_test, sup_y_train, sup_y_test        = train_test_split(sup_X, sup_y, test_size = 0.2, random_state=42)\n",
    "deep_X_train, deep_X_test, deep_y_train, deep_y_test    = train_test_split(deep_X, deep_y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# sm = SMOTE(random_state=42, k_neighbors=150)\n",
    "# cc_X_train, cc_y_train = sm.fit_resample(cc_X_train, cc_y_train)\n",
    "\n",
    "# sm = SMOTE(random_state=42, k_neighbors=150)\n",
    "# sup_X_train, sup_y_train = sm.fit_resample(sup_X_train, sup_y_train)\n",
    "\n",
    "# sm = SMOTE(random_state=42, k_neighbors=150)\n",
    "# deep_X_train, deep_y_train = sm.fit_resample(deep_X_train, deep_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_X_train    = cc_preprocess.fit_transform(cc_X_train)\n",
    "# sup_X_train   = sup_preprocess.fit_transform(sup_X_train)\n",
    "# deep_X_train  = deep_preprocess.fit_transform(deep_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def make_LR_model(X_train, y_train) :\n",
    "\n",
    "    lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "    param = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}\n",
    "\n",
    "    lr_grid = GridSearchCV(lr_model, param, scoring='f1_samples')\n",
    "    \n",
    "    lr_grid.fit(X_train, y_train)\n",
    "    print(lr_grid.best_params_)\n",
    "    \n",
    "    return lr_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def make_SVC_model(X_train, y_train) :\n",
    "    svc = SVC(random_state=42)\n",
    "\n",
    "    param = {\n",
    "        'C'         :[0.1,1,10,100],\n",
    "        'gamma'     :[1,0.1,0.001],\n",
    "        'kernel'    :['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "\n",
    "\n",
    "    svc_grid = GridSearchCV(svc, param)\n",
    "        \n",
    "    svc_grid.fit(X_train, y_train)\n",
    "    print(svc_grid.best_params_)\n",
    "    \n",
    "    return svc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2'}\n",
      "{'C': 0.001, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1146, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1287, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1577, in precision_recall_fscore_support\n",
      "    MCM = multilabel_confusion_matrix(\n",
      "  File \"c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 509, in multilabel_confusion_matrix\n",
      "    raise ValueError(\n",
      "ValueError: Samplewise metrics are not available outside of multilabel classification.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cc_model   = make_LR_model(cc_X_train, cc_y_train)\n",
    "sup_model  = make_LR_model(sup_X_train, sup_y_train)\n",
    "deep_model = make_LR_model(deep_X_train, deep_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_model   = LogisticRegression(random_state=42, C=1000, penalty='l1', solver='liblinear').fit(cc_X_train, cc_y_train)\n",
    "# sup_model  = LogisticRegression(random_state=42, C=1000, penalty='l1', solver='liblinear').fit(sup_X_train, sup_y_train)\n",
    "# deep_model = LogisticRegression(random_state=42, C=1000, penalty='l1', solver='liblinear').fit(deep_X_train, deep_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_y_pred   = cc_model.predict(cc_X)\n",
    "sup_y_pred  = sup_model.predict(sup_X)\n",
    "deep_y_pred = deep_model.predict(deep_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.66       202\n",
      "           1       0.47      0.35      0.40       162\n",
      "           2       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.53       420\n",
      "   macro avg       0.34      0.39      0.36       420\n",
      "weighted avg       0.45      0.53      0.47       420\n",
      "\n",
      "[[166  36   0]\n",
      " [105  57   0]\n",
      " [ 27  29   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "all_pred = cc_model.predict(cc_X_test)\n",
    "\n",
    "print(classification_report(cc_y_test, all_pred))\n",
    "print(confusion_matrix(cc_y_test, all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_y_pred_test   = cc_model.predict(cc_X_test)\n",
    "sup_y_pred_test  = sup_model.predict(sup_X_test)\n",
    "deep_y_pred_test = deep_model.predict(deep_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in range(len(cc_y_pred_test)) :\n",
    "    if cc_y_pred_test[i] == deep_y_pred_test[i] :\n",
    "        y_pred.append(cc_y_pred_test[i])\n",
    "    else :\n",
    "        y_pred.append(sup_y_pred_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.85      0.65       202\n",
      "           1       0.48      0.27      0.35       162\n",
      "           2       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.51       420\n",
      "   macro avg       0.34      0.37      0.33       420\n",
      "weighted avg       0.44      0.51      0.45       420\n",
      "\n",
      "[[172  30   0]\n",
      " [118  44   0]\n",
      " [ 39  17   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(cc_y_test, y_pred))\n",
    "print(confusion_matrix(cc_y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with all depth + New Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = []\n",
    "\n",
    "for i in range(len(cc_y_pred)) :\n",
    "    all_X.append([age[i], sexe[i], cc_y_pred[i], sup_y_pred[i], deep_y_pred[i]])\n",
    "    \n",
    "all_X = pd.DataFrame(all_X, columns=['age','sex', 'cc_pred','sup_pred', 'deep_pred'])\n",
    "all_y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def all_make_preprocessor(numeric_columns, categorical_columns):\n",
    "\n",
    "    numeric_transformer     = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        # ('pca', PCA(n_components=find_nb_pca(data, numeric_columns))),    \n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('encoder', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_columns),\n",
    "            ('categorical', categorical_transformer, categorical_columns),            \n",
    "        ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns     = ['age']\n",
    "binary_columns      = ['Sexe']\n",
    "categorical_columns = [col for col in all_X.columns if col not in numeric_columns + binary_columns]\n",
    "\n",
    "all_preprocessor    = all_make_preprocessor(numeric_columns, categorical_columns)\n",
    "\n",
    "all_X = all_preprocessor.fit_transform(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "all_model   = make_forest_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       202\n",
      "           1       0.75      0.78      0.77       162\n",
      "           2       0.75      0.64      0.69        56\n",
      "\n",
      "    accuracy                           0.80       420\n",
      "   macro avg       0.79      0.76      0.77       420\n",
      "weighted avg       0.80      0.80      0.80       420\n",
      "\n",
      "[[175  25   2]\n",
      " [ 25 127  10]\n",
      " [  2  18  36]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "all_pred = all_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, all_pred))\n",
    "print(confusion_matrix(y_test, all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06428571428571428"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27/420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep = cc_preprocess.transform(pd.DataFrame([[90, 1]], columns=['age', 'Sexe']))\n",
    "# prep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_iHeath_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
