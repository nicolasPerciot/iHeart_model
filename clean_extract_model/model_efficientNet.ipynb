{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the path_dir below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = os.path.dirname(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(os.path.join(path_dir, 'scripts\\\\common'))\n",
    "import tool\n",
    "\n",
    "\n",
    "path_images    = os.path.join(path_dir, 'data\\\\images')\n",
    "\n",
    "dataset = pd.read_csv(os.path.join(path_dir, 'data\\\\sheet\\\\data_final_lite.csv'))\n",
    "dataset = dataset.loc[:, ['ID', 'CHA2DS2-VASc', 'Age', 'Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "\n",
    "image_size  = (SIZE, SIZE, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "error_images       = []\n",
    "patient_id_list    = []\n",
    "dir_dirs = []\n",
    "def find_images(name) :\n",
    "    data        = []\n",
    "    \n",
    "\n",
    "    for dir_client in os.listdir(path_images) :\n",
    "        path_client = os.path.join(path_images, dir_client)\n",
    "        for dirs in os.listdir(path_client) :\n",
    "            if dirs.lower().find(name) != -1 :\n",
    "                image = cv.imread(os.path.join(path_client, dirs))\n",
    "                image = cv.resize(image, (SIZE, SIZE), interpolation = cv.INTER_LINEAR)\n",
    "                                \n",
    "                if(image[image.astype(bool)].size != 0) :\n",
    "                    try :\n",
    "                        age     = round(dataset['Age'][dataset['ID'] == dir_client].values[0])\n",
    "                        sexe    = int(dataset['Sex'][dataset['ID'] == dir_client].values[0])\n",
    "                        target  = dataset['CHA2DS2-VASc'][dataset['ID'] == dir_client].values[0]\n",
    "                        \n",
    "                        patient_id_list.append(dir_client)\n",
    "                        data.append([image, age, sexe, target])\n",
    "                        if dir_dirs not in error_images :\n",
    "                            dir_dirs.append(dirs)\n",
    "                    except :\n",
    "                        if dir_client not in error_images :\n",
    "                            error_images.append(dir_client)\n",
    "                        continue\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['image', 'age', 'sex', 'target']\n",
    "\n",
    "cc_images     = pd.DataFrame(find_images('cc'), columns=columns)\n",
    "sup_images    = pd.DataFrame(find_images('sup'), columns=columns)\n",
    "deep_images   = pd.DataFrame(find_images('deep'), columns=columns)\n",
    "\n",
    "\n",
    "cc_y    = cc_images.iloc[:, -1]\n",
    "cc_X    = cc_images.iloc[:, :-1]\n",
    "\n",
    "sup_y   = sup_images.iloc[:, -1]\n",
    "sup_X   = sup_images.iloc[:, :-1]\n",
    "\n",
    "deep_y  = deep_images.iloc[:, -1]\n",
    "deep_X  = deep_images.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "age         = cc_images.iloc[:, -3]\n",
    "sex         = cc_images.iloc[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_col(data, add_col=True) :\n",
    "    columns = []\n",
    "    for col in data.columns.to_list() :\n",
    "        columns.append(str(col))\n",
    "       \n",
    "    # if add_col : \n",
    "    #     new_columns = columns[:-2]\n",
    "    #     new_columns.append('age')\n",
    "    #     new_columns.append('sex')\n",
    "    #     columns = new_columns\n",
    "\n",
    "    data.columns = columns\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction + Classification per depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_col(X, binary_columns=[], categorical_columns=[]) :\n",
    "    \n",
    "    numeric_columns = []\n",
    "    for elem in X.columns.to_list():\n",
    "        if elem not in binary_columns and elem not in categorical_columns :\n",
    "            numeric_columns.append(elem)\n",
    "    return numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(data, binary_columns=[]):\n",
    "    \n",
    "    numeric_columns     = find_num_col(data, binary_columns=binary_columns)\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=tool.find_nb_pca(data, numeric_columns))),    \n",
    "    ])\n",
    "\n",
    "    preprocessor        = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_columns),\n",
    "        ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.util import random_noise\n",
    "\n",
    "  \n",
    "def form_image(image) :\n",
    "    # image = image / 255.\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def predict_image(image, model) :    \n",
    "    form_data = []\n",
    "    for elem in model.predict(image)[0] :\n",
    "        form_data.append(elem)\n",
    "    return form_data\n",
    "  \n",
    "def image_augmentation(images, model) :\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(images)) :\n",
    "        \n",
    "        data.append(predict_image(form_image(images[i]), model))\n",
    "\n",
    "        # data.append(predict_image(form_image(adjust_gamma(images[i], gamma=0.5,gain=1)), model), age, sex)\n",
    "        # data.append(predict_image(form_image(adjust_gamma(images[i], gamma=2,gain=1)), model), age, sex)\n",
    "        \n",
    "        data.append(predict_image(form_image(np.fliplr(images[i])), model))\n",
    "        # data.append(predict_image(form_image(np.flipud(images[i])), model))\n",
    "        \n",
    "        # data.append(predict_image(form_image(random_noise(images[i])), model), age, sex)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(X, y, image_augment=False, extraction_model=None) :\n",
    "    \n",
    "    if extraction_model == None :\n",
    "        efficient_model     = EfficientNetB0(weights=None)\n",
    "        extraction_model    = Model(inputs=efficient_model.inputs, outputs=efficient_model.layers[-2].output)\n",
    "    \n",
    "    if image_augment :      \n",
    "        ages                = X['age'].to_list()\n",
    "        gender              = X['sex'].to_list()\n",
    "        \n",
    "        len_before          = X.shape[0]\n",
    "        X                   = pd.DataFrame(image_augmentation(X['image'], extraction_model))        \n",
    "        len_after           = X.shape[0]    \n",
    "        \n",
    "        image_augment       = int(len_after / len_before)\n",
    "        \n",
    "        X['age']            = [ages[i] for i in range(len_before) for j in range(image_augment)]\n",
    "        X['sex']            = [gender[i] for i in range(len_before) for j in range(image_augment)]\n",
    "        y                   = [y[i] for i in range(len_before) for j in range(image_augment)]\n",
    "    \n",
    "    else :\n",
    "        tmp_X = []\n",
    "        for i in range(X.shape[0]) :\n",
    "            tmp_X.append(predict_image(form_image(X['image'][i]), extraction_model))\n",
    "            \n",
    "        tmp_X               = pd.DataFrame(tmp_X)\n",
    "        tmp_X['age']        = X['age']\n",
    "        tmp_X['sex']        = X['sex']\n",
    "        X                   = tmp_X\n",
    "    \n",
    "    X     = form_col(X, False)\n",
    "    \n",
    "    preprocessor = make_preprocessor(X)\n",
    "    \n",
    "    X = preprocessor.fit_transform(X)\n",
    "    return X, y, image_augment, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_col(X, binary_columns=[], categorical_columns=[]) :\n",
    "    \n",
    "    numeric_columns = []\n",
    "    for elem in X.columns.to_list():\n",
    "        if elem not in binary_columns and elem not in categorical_columns :\n",
    "            numeric_columns.append(elem)\n",
    "    return numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "forest_param = {\n",
    "        'bootstrap'         : [False, True],\n",
    "        'ccp_alpha'         : [.001, 0.1, 1],\n",
    "        'n_estimators'      : [25, 50, 100],\n",
    "        'criterion'         : ['gini', 'entropy', 'log_loss']\n",
    "        }\n",
    "\n",
    "LR_param = {\n",
    "    'C'         : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty'   : ['l1', 'l2'],\n",
    "#     'max_iter'  : list(range(100,800,100)),\n",
    "    'solver'    : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "svc_param = {\n",
    "    'C'         :[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'gamma'     :[1,0.1,0.001,0.0001],\n",
    "    'kernel'    :['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_X = pd.DataFrame()\n",
    "\n",
    "cc_X['age'] = age\n",
    "cc_X['sex'] = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m index_train, index_test                 \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39mdataset_split_index(cc_X, cc_y, fold\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m cc_X, cc_y, cc_image_augment, cc_preprocessor               \u001b[39m=\u001b[39m preprocess_image(cc_X, cc_y)\n\u001b[0;32m      4\u001b[0m sup_X, sup_y, sup_image_augment, sup_preprocessor           \u001b[39m=\u001b[39m preprocess_image(sup_X, sup_y)\n\u001b[0;32m      5\u001b[0m deep_X, deep_y, deep_image_augment, deep_preprocessor       \u001b[39m=\u001b[39m preprocess_image(deep_X, deep_y)\n",
      "Cell \u001b[1;32mIn[67], line 63\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(X, y, image_augment, extraction_model)\u001b[0m\n\u001b[0;32m     61\u001b[0m tmp_X \u001b[39m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) :\n\u001b[1;32m---> 63\u001b[0m     tmp_X\u001b[39m.\u001b[39mappend(predict_image(form_image(X[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m][i]), extraction_model))\n\u001b[0;32m     65\u001b[0m tmp_X               \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(tmp_X)\n\u001b[0;32m     66\u001b[0m tmp_X[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m]        \u001b[39m=\u001b[39m X[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "index_train, index_test                 = tool.dataset_split_index(cc_X, cc_y, fold=5)\n",
    "\n",
    "cc_X, cc_y, cc_image_augment, cc_preprocessor               = preprocess_image(cc_X, cc_y)\n",
    "sup_X, sup_y, sup_image_augment, sup_preprocessor           = preprocess_image(sup_X, sup_y)\n",
    "deep_X, deep_y, deep_image_augment, deep_preprocessor       = preprocess_image(deep_X, deep_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(deep_preprocessor, open('C:\\\\Users\\\\nperc\\\\Documents\\\\Datathon\\\\clean_deep_model\\\\data\\\\models\\\\deep_preprocess.h5', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cc_X, cc_y, test_size=0.2, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(model, forest_param)\n",
    "\n",
    "model = grid.fit(X_train, cc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7724137931034483\n",
      "[[83  5  0]\n",
      " [ 9 17  8]\n",
      " [ 0 11 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print('Accuracy : ' + str(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_report, cc_index_fold         = tool.find_best_grid(\n",
    "        model, cc_X, cc_y, index_train, index_test,\n",
    "        param=forest_param)\n",
    "\n",
    "sup_report, sup_index_fold       = tool.find_best_grid(\n",
    "        model, sup_X, sup_y, index_train, index_test,\n",
    "        param=forest_param)\n",
    "\n",
    "deep_report, deep_index_fold     = tool.find_best_grid(\n",
    "        model, deep_X, deep_y, index_train, index_test,\n",
    "        param=forest_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_pred(model, report, X, y, index_fold) :\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model       = model(**report['best_grid'], random_state=42)\n",
    "    z\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred      = model.predict(X_test)\n",
    "    \n",
    "    print('Mean accuracy : ' + str(report['best_mean_score']))\n",
    "    print('Standard deviation : ' + str(report['best_st_score']))\n",
    "    print('Accuracy : ' + str(accuracy_score(y_test, y_pred)))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc_pred, cc_model = train_pred(RandomForestClassifier, cc_report, cc_X, cc_y, cc_index_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sklearn.ensemble._forest.ExtraTreesClassifier() argument after ** must be a mapping, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sup_pred, sup_model \u001b[39m=\u001b[39m train_pred(ExtraTreesClassifier, sup_report, sup_X, sup_y, sup_index_fold)\n",
      "Cell \u001b[1;32mIn[52], line 8\u001b[0m, in \u001b[0;36mtrain_pred\u001b[1;34m(model, report, X, y, index_fold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_pred\u001b[39m(model, report, X, y, index_fold) :\n\u001b[0;32m      6\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     model       \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreport[\u001b[39m'\u001b[39m\u001b[39mbest_grid\u001b[39m\u001b[39m'\u001b[39m], random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m     y_pred      \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: sklearn.ensemble._forest.ExtraTreesClassifier() argument after ** must be a mapping, not str"
     ]
    }
   ],
   "source": [
    "sup_pred, sup_model = train_pred(RandomForestClassifier, sup_report, sup_X, sup_y, sup_index_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy : 0.7759961685823755\n",
      "Standard deviation : 0.03792559657602957\n",
      "Accuracy : 0.7931034482758621\n",
      "[[82  6  0]\n",
      " [ 8 25  1]\n",
      " [ 0 15  8]]\n"
     ]
    }
   ],
   "source": [
    "deep_pred, deep_model = train_pred(ExtraTreesClassifier, deep_report, deep_X, deep_y, deep_index_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with all depth + New Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m all_X \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(cc_y_pred)) :\n\u001b[0;32m      4\u001b[0m     all_X\u001b[39m.\u001b[39mappend([cc_y_pred[i], sup_y_pred[i], deep_y_pred[i]])\n\u001b[0;32m      6\u001b[0m all_X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_X, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcc_pred\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msup_pred\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdeep_pred\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cc_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "all_X = []\n",
    "\n",
    "for i in range(len(cc_y_pred)) :\n",
    "    all_X.append([cc_y_pred[i], sup_y_pred[i], deep_y_pred[i]])\n",
    "\n",
    "all_X = pd.DataFrame(all_X, columns=['cc_pred','sup_pred', 'deep_pred'])\n",
    "all_y = cc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def all_make_preprocessor(numeric_columns, categorical_columns):\n",
    "\n",
    "    # numeric_transformer     = Pipeline(steps=[\n",
    "    #     ('imputer', SimpleImputer(strategy='median')),\n",
    "    #     ('scaler', StandardScaler()),\n",
    "    #     # ('pca', PCA(n_components=find_nb_pca(data, numeric_columns))),    \n",
    "    # ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('encoder', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # ('numeric', numeric_transformer, numeric_columns),\n",
    "            ('categorical', categorical_transformer, categorical_columns),            \n",
    "        ])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns     = ['Age']\n",
    "binary_columns      = ['Sex']\n",
    "categorical_columns = [col for col in all_X.columns if col not in numeric_columns + binary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data_train, data_test, labels_train, labels_test, index_train, index_test = train_test_split(all_X, all_y, all_X.index, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preprocessor    = all_make_preprocessor(numeric_columns, categorical_columns)\n",
    "\n",
    "all_X = all_preprocessor.fit_transform(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train, index_test                 = tool.dataset_split_index(cc_X, cc_y)\n",
    "\n",
    "cc_X_train = cc_X.iloc[index_train[0], :]\n",
    "cc_y_train = cc_y[index_train[0]]\n",
    "\n",
    "cc_X_test = cc_X.iloc[index_test[0], :]\n",
    "cc_y_test = cc_y[index_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(all_X, all_y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def make_forest_model(X_train, y_train) :\n",
    "    forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    forest_param = {\n",
    "        'bootstrap'         : [True],\n",
    "        'max_depth'         : [5, 8, 12, 15, 20],\n",
    "        'ccp_alpha'         : [.001],\n",
    "        'n_estimators'      : [25, 50, 100],\n",
    "        'criterion'         : ['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "    forest_grid = GridSearchCV(forest_model, forest_param)\n",
    "    \n",
    "    forest_grid.fit(X_train, y_train)\n",
    "    print(forest_grid.best_params_)\n",
    "    \n",
    "    return forest_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.001, 'criterion': 'gini', 'max_depth': 8, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "all_model   = make_forest_model(cc_X_train, cc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_estimator, all_report         = tool.train_model(LogisticRegression(), all_X, all_y, index_train, index_test, param=LR_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        88\n",
      "           1       0.00      0.00      0.00        34\n",
      "           2       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.61       145\n",
      "   macro avg       0.20      0.33      0.25       145\n",
      "weighted avg       0.37      0.61      0.46       145\n",
      "\n",
      "[[88  0  0]\n",
      " [34  0  0]\n",
      " [23  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nperc\\Documents\\Datathon\\01_iHeath_env2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "all_pred = all_model.predict(cc_X_test)\n",
    "\n",
    "print(classification_report(cc_y_test, all_pred))\n",
    "print(confusion_matrix(cc_y_test, all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1554054054054054"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep = cc_preprocess.transform(pd.DataFrame([[90, 1]], columns=['age', 'Sexe']))\n",
    "# prep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01_iHeath_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
